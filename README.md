# paper-reading

#This repository is used to record summaries of papers I have read.

Paper:[Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning](https://arxiv.org/pdf/1712.05526v1.pdf)
Contribution: 
  1.两种攻击方式：a single instance和 a pattern as the key；二者都只需要对training dataset注入少量的poisoning samples就可以对模型实现物理攻击
  2.black box，不需要知道模型的具体参数架构情况
